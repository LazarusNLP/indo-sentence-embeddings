{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Indonesian Sentence Embeddings","text":"<p>Inspired by Thai Sentence Vector Benchmark, we decided to embark on the journey of training Indonesian sentence embedding models!</p> <p> </p> <p>To the best of our knowledge, there is no official benchmark on Indonesian sentence embeddings. We hope this repository can serve as a benchmark for future research on Indonesian sentence embeddings.</p>"},{"location":"#evaluation","title":"Evaluation","text":""},{"location":"#machine-translated-sts-b","title":"Machine Translated STS-B","text":"<p>We believe that a synthetic baseline is better than no baseline. Therefore, we followed approached done in the Thai Sentence Vector Benchmark project and translated the STS-B dev and test set to Indonesian via Google Translate API. This dataset will be used to evaluate our model's Spearman correlation score on the translated test set.</p> <p>You can find the translated dataset on \ud83e\udd17 HuggingFace Hub.</p> <p>Moreover, we will further evaluate the transferrability of our models on downstream tasks (e.g. text classification, natural language inference, etc.) and compare them with existing pre-trained language models (PLMs).</p>"},{"location":"#text-classification","title":"Text Classification","text":"<p>For text classification, we will be doing emotion classification and sentiment analysis on the EmoT and SmSA subsets of IndoNLU, respectively. To do so, we will be doing the same approach as Thai Sentence Vector Benchmark and simply fit a Linear SVC on sentence representations of our texts with their corresponding labels. Thus, unlike conventional fine-tuning method where the backbone model is also updated, the Sentence Transformer stays frozen in our case; with only the classification head being trained.</p>"},{"location":"#methods","title":"Methods","text":""},{"location":"#unsupervised-simcse","title":"(Unsupervised) SimCSE","text":"<p>We followed SimCSE: Simple Contrastive Learning of Sentence Embeddings and trained a sentence embedding model in an unsupervised fashion. Unsupervised SimCSE allows us to leverage an unsupervised corpus -- which are plenty -- and with different dropout masks in the encoder, contrastively learn sentence representations. This is parallel with the situation that there is a lack of supervised Indonesian sentence similarity datasets, hence SimCSE is a natural first move into this field. We used the Sentence Transformer implementation of SimCSE.</p>"},{"location":"#congen","title":"ConGen","text":"<p>Like SimCSE, ConGen: Unsupervised Control and Generalization Distillation For Sentence Representation is another unsupervised technique to train a sentence embedding model. Since it is in-part a distillation method, ConGen relies on a teacher model which will then be distilled to a student model. The original paper proposes back-translation as the best data augmentation technique. However, due to the lack of resources, we implemented word deletion, which was found to be on-par with back-translation despite being trivial. We used the official ConGen implementation which was written on top of the Sentence Transformers library.</p>"},{"location":"#results","title":"Results","text":""},{"location":"#machine-translated-indonesian-semantic-textual-similarity-benchmark-stsb-mt-id","title":"Machine Translated Indonesian Semantic Textual Similarity Benchmark (STSB-MT-ID)","text":"Model Spearman's Correlation (%) #params Base/Student Model Teacher Model Train Dataset Supervised SimCSE-IndoBERT Lite Base 44.08 12M IndoBERT Lite Base N/A Wikipedia SimCSE-IndoRoBERTa Base 61.26 125M IndoRoBERTa Base N/A Wikipedia SimCSE-IndoBERT Base 70.13 125M IndoBERT Base N/A Wikipedia ConGen-IndoBERT Lite Base 79.97 12M IndoBERT Lite Base paraphrase-multilingual-mpnet-base-v2 Wikipedia ConGen-IndoBERT Base 80.47 125M IndoBERT Base paraphrase-multilingual-mpnet-base-v2 Wikipedia ConGen-SimCSE-IndoBERT Base 81.16 125M SimCSE-IndoBERT Base paraphrase-multilingual-mpnet-base-v2 Wikipedia S-IndoBERT Base mMARCO 72.95 125M IndoBERT Base N/A mMARCO \u2705 distiluse-base-multilingual-cased-v2 75.08 134M DistilBERT Base Multilingual mUSE See: SBERT \u2705 paraphrase-multilingual-mpnet-base-v2 83.83 125M XLM-RoBERTa Base paraphrase-mpnet-base-v2 See: SBERT \u2705"},{"location":"#emotion-classification-emot","title":"Emotion Classification (EmoT)","text":"Model Accuracy (%) F1 Macro (%) SimCSE-IndoBERT Lite Base 41.13 40.70 SimCSE-IndoRoBERTa Base 50.45 50.75 SimCSE-IndoBERT Base 55.45 55.78 ConGen-IndoBERT Lite Base 58.18 58.84 ConGen-IndoBERT Base 57.04 57.06 ConGen-SimCSE-IndoBERT Base 59.54 60.37 S-IndoBERT Base mMARCO 48.86 47.92 distiluse-base-multilingual-cased-v2 63.63 64.13 paraphrase-multilingual-mpnet-base-v2 63.18 63.78"},{"location":"#sentiment-analysis-smsa","title":"Sentiment Analysis (SmSA)","text":"Model Accuracy (%) F1 Macro (%) SimCSE-IndoBERT Lite Base 68.8 63.37 SimCSE-IndoRoBERTa Base 76.2 70.42 SimCSE-IndoBERT Base 85.6 81.50 ConGen-IndoBERT Lite Base 81.2 75.59 ConGen-IndoBERT Base 85.4 82.12 ConGen-SimCSE-IndoBERT Base 83.0 78.74 S-IndoBERT Base mMARCO 80.2 75.73 distiluse-base-multilingual-cased-v2 78.8 73.64 paraphrase-multilingual-mpnet-base-v2 89.6 86.56"},{"location":"#references","title":"References","text":"<pre><code>@misc{Thai-Sentence-Vector-Benchmark-2022,\nauthor = {Limkonchotiwat, Peerat},\ntitle = {Thai-Sentence-Vector-Benchmark},\nyear = {2022},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished = {\\url{https://github.com/mrpeerat/Thai-Sentence-Vector-Benchmark}}\n}\n</code></pre> <pre><code>@inproceedings{reimers-2019-sentence-bert,\ntitle = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\nauthor = \"Reimers, Nils and Gurevych, Iryna\",\nbooktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\nmonth = \"11\",\nyear = \"2019\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://arxiv.org/abs/1908.10084\",\n}\n</code></pre> <pre><code>@inproceedings{gao2021simcse,\ntitle={{SimCSE}: Simple Contrastive Learning of Sentence Embeddings},\nauthor={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},\nbooktitle={Empirical Methods in Natural Language Processing (EMNLP)},\nyear={2021}\n}\n</code></pre> <pre><code>@inproceedings{limkonchotiwat-etal-2022-congen,\ntitle = \"{ConGen}: Unsupervised Control and Generalization Distillation For Sentence Representation\",\nauthor = \"Limkonchotiwat, Peerat  and\n    Ponwitayarat, Wuttikorn  and\n    Lowphansirikul, Lalita and\n    Udomcharoenchaikit, Can  and\n    Chuangsuwanich, Ekapol  and\n    Nutanong, Sarana\",\nbooktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\nyear = \"2022\",\npublisher = \"Association for Computational Linguistics\",\n}\n</code></pre>"},{"location":"applications/text_classification/","title":"Text Classification","text":"<p>Normally, sentence embedding models are leveraged for downstream tasks such as information retrieval, semantic search, clustering, etc. Text classification could similarly leverage these models' sentence embedding capabilities.</p> <p>We will be doing emotion classification and sentiment analysis on the EmoT and SmSA subsets of IndoNLU, respectively. To do so, we will be doing the same approach as Thai Sentence Vector Benchmark and simply fit a Linear SVC on sentence representations of our texts with their corresponding labels. Thus, unlike conventional fine-tuning method where the backbone model is also updated, the Sentence Transformer stays frozen in our case; with only the classification head being trained.</p>"},{"location":"applications/text_classification/#emotion-classification-emot-with-svc","title":"Emotion Classification (EmoT) with SVC","text":"<pre><code>python transfer_text_classification.py \\\n--model-name LazarusNLP/simcse-indobert-base \\\n--dataset-name indonlp/indonlu \\\n--dataset-config emot \\\n--train-split-name train \\\n--test-split-name test \\\n--text-column tweet \\\n--label-column label\n</code></pre>"},{"location":"applications/text_classification/#results","title":"Results","text":"Model Accuracy (%) F1 Macro (%) SimCSE-IndoBERT Lite Base 41.13 40.70 SimCSE-IndoRoBERTa Base 50.45 50.75 SimCSE-IndoBERT Base 55.45 55.78 ConGen-IndoBERT Lite Base 58.18 58.84 ConGen-IndoBERT Base 57.04 57.06 ConGen-SimCSE-IndoBERT Base 59.54 60.37 S-IndoBERT Base mMARCO 48.86 47.92 distiluse-base-multilingual-cased-v2 63.63 64.13 paraphrase-multilingual-mpnet-base-v2 63.18 63.78"},{"location":"applications/text_classification/#sentiment-analysis-smsa-with-svc","title":"Sentiment Analysis (SmSA) with SVC","text":"<pre><code>python transfer_text_classification.py \\\n--model-name LazarusNLP/simcse-indobert-base \\\n--dataset-name indonlp/indonlu \\\n--dataset-config smsa \\\n--train-split-name train \\\n--test-split-name test \\\n--text-column text \\\n--label-column label\n</code></pre>"},{"location":"applications/text_classification/#results_1","title":"Results","text":"Model Accuracy (%) F1 Macro (%) SimCSE-IndoBERT Lite Base 68.8 63.37 SimCSE-IndoRoBERTa Base 76.2 70.42 SimCSE-IndoBERT Base 85.6 81.50 ConGen-IndoBERT Lite Base 81.2 75.59 ConGen-IndoBERT Base 85.4 82.12 ConGen-SimCSE-IndoBERT Base 83.0 78.74 S-IndoBERT Base mMARCO 80.2 75.73 distiluse-base-multilingual-cased-v2 78.8 73.64 paraphrase-multilingual-mpnet-base-v2 89.6 86.56"},{"location":"applications/text_classification/#references","title":"References","text":"<pre><code>@misc{Thai-Sentence-Vector-Benchmark-2022,\nauthor = {Limkonchotiwat, Peerat},\ntitle = {Thai-Sentence-Vector-Benchmark},\nyear = {2022},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished = {\\url{https://github.com/mrpeerat/Thai-Sentence-Vector-Benchmark}}\n}\n</code></pre> <pre><code>@inproceedings{wilie2020indonlu,\ntitle={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\nauthor={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\nbooktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\nyear={2020}\n}\n</code></pre>"},{"location":"evaluation/evaluation/","title":"Evaluation","text":""},{"location":"evaluation/evaluation/#machine-translated-sts-b","title":"Machine Translated STS-B","text":"<p>To the best of our knowledge, there is no official benchmark on Indonesian sentence embeddings. Inspired by Thai Sentence Vector Benchmark, we translated the STS-B dev and test set to Indonesian via Google Translate API. This dataset will be used to evaluate our model's Spearman correlation score on the translated test set. You can find the translated dataset on \ud83e\udd17 HuggingFace Hub.</p> <p>For practical purposes, we used Sentence Transformer's <code>EmbeddingSimilarityEvaluator</code> to perform inference and evaluate our models.</p>"},{"location":"evaluation/evaluation/#example","title":"Example","text":"<pre><code>python eval_sts.py \\\n--model-name LazarusNLP/congen-indobert-base \\\n--test-dataset-name LazarusNLP/stsb_mt_id \\\n--test-dataset-split test \\\n--test-text-column-1 text_1 \\\n--test-text-column-2 text_2 \\\n--test-label-column correlation \\\n--test-batch-size 32\n</code></pre>"},{"location":"evaluation/evaluation/#references","title":"References","text":"<pre><code>@misc{Thai-Sentence-Vector-Benchmark-2022,\nauthor = {Limkonchotiwat, Peerat},\ntitle = {Thai-Sentence-Vector-Benchmark},\nyear = {2022},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished = {\\url{https://github.com/mrpeerat/Thai-Sentence-Vector-Benchmark}}\n}\n</code></pre> <pre><code>@inproceedings{reimers-2019-sentence-bert,\ntitle = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\nauthor = \"Reimers, Nils and Gurevych, Iryna\",\nbooktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\nmonth = \"11\",\nyear = \"2019\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://arxiv.org/abs/1908.10084\",\n}\n</code></pre>"},{"location":"training/mMARCO/","title":"mMARCO","text":"<p>mMARCO is a multilingual version of the MS MARCO passage ranking dataset, translated via Google Translate API. It supports up to 14 languages, including Indonesian. </p> <p>Unlike the original MS MARCO dataset, this version only has query-positive-negative triplets. In the original version, for instance, it had a list of passages which may be relevant to the query, and a label for the most relevant passage.</p>"},{"location":"training/mMARCO/#bi-encoder-with-multiplenegativesrankingloss","title":"Bi-Encoder with MultipleNegativesRankingLoss","text":""},{"location":"training/mMARCO/#indobert-base","title":"IndoBERT Base","text":"<pre><code>python train_bi-encoder_mmarco_mnrl.py \\\n--model-name indobenchmark/indobert-base-p1 \\\n--train-dataset-name unicamp-dl/mmarco \\\n--train-dataset-config indonesian \\\n--max-seq-length 32 \\\n--max-train-samples 1000000 \\\n--num-epochs 5 \\\n--train-batch-size 128 \\\n--learning-rate 2e-5 \\\n--warmup-ratio 0.1\n</code></pre>"},{"location":"training/mMARCO/#results","title":"Results","text":""},{"location":"training/mMARCO/#stsb-mt-id","title":"STSB-MT-ID","text":"Model Spearman's Correlation (%) #params Base Model S-IndoBERT Base mMARCO 72.95 125M IndoBERT Base"},{"location":"training/mMARCO/#references","title":"References","text":"<pre><code>@misc{bonifacio2021mmarco,\ntitle={mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset}, author={Luiz Henrique Bonifacio and Vitor Jeronymo and Hugo Queiroz Abonizio and Israel Campiotti and Marzieh Fadaee and  and Roberto Lotufo and Rodrigo Nogueira},\nyear={2021},\neprint={2108.13897},\narchivePrefix={arXiv},\nprimaryClass={cs.CL}\n}\n</code></pre>"},{"location":"unsupervised_learning/ConGen/","title":"ConGen","text":"<p>ConGen is an unsupervised, knowledge distillation technique that aims to control and generalize smaller student model from a larger sentence embedding teacher model. In short, the technique enforces the student model to mimic the logits of the teacher model on an instance queue subset of the training data (control) and also generalize it to augmentations of texts for robustness.</p> <p>Training via ConGen requires an unsupervised corpus, which is readily available for Indonesian texts. In our experiments, we used Wikipedia texts. As for the data augmentation method, Limkonchotiwat et al. (2022) proposed using back-translation via an NMT model or Google Translate API. However, since that is costly to compute for 1 million texts, we opted for a simple single-word deletion technique.</p>"},{"location":"unsupervised_learning/ConGen/#congen-with-single-word-deletion","title":"ConGen with Single-word Deletion","text":""},{"location":"unsupervised_learning/ConGen/#indobert-base","title":"IndoBERT Base","text":"<pre><code>python train_con_gen.py \\\n--model-name indobenchmark/indobert-base-p1 \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-seq-length 32 \\\n--max-train-samples 1000000 \\\n--num-epochs 20 \\\n--train-batch-size 128 \\\n--early-stopping-patience 7 \\\n--learning-rate 1e-4 \\\n--teacher-model-name sentence-transformers/paraphrase-multilingual-mpnet-base-v2 \\\n--queue-size 65536 \\\n--student-temp 0.5 \\\n--teacher-temp 0.5\n</code></pre>"},{"location":"unsupervised_learning/ConGen/#indobert-lite-base","title":"IndoBERT Lite Base","text":"<pre><code>python train_con_gen.py \\\n--model-name indobenchmark/indobert-lite-base-p1 \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-seq-length 32 \\\n--max-train-samples 1000000 \\\n--num-epochs 20 \\\n--train-batch-size 128 \\\n--early-stopping-patience 7 \\\n--learning-rate 3e-4 \\\n--teacher-model-name sentence-transformers/paraphrase-multilingual-mpnet-base-v2 \\\n--queue-size 65536 \\\n--student-temp 0.05 \\\n--teacher-temp 0.05\n</code></pre>"},{"location":"unsupervised_learning/ConGen/#simcse-indobert-base","title":"SimCSE-IndoBERT Base","text":"<pre><code>python train_con_gen.py \\\n--model-name LazarusNLP/simcse-indobert-base \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-seq-length 32 \\\n--max-train-samples 1000000 \\\n--num-epochs 20 \\\n--train-batch-size 128 \\\n--early-stopping-patience 7 \\\n--learning-rate 1e-4 \\\n--teacher-model-name sentence-transformers/paraphrase-multilingual-mpnet-base-v2 \\\n--queue-size 65536 \\\n--student-temp 0.5 \\\n--teacher-temp 0.5\n</code></pre>"},{"location":"unsupervised_learning/ConGen/#results","title":"Results","text":""},{"location":"unsupervised_learning/ConGen/#stsb-mt-id","title":"STSB-MT-ID","text":"Model Spearman's Correlation (%) #params Base/Student Model Teacher Model Train Dataset ConGen-IndoBERT Lite Base 79.97 12M IndoBERT Lite Base paraphrase-multilingual-mpnet-base-v2 Wikipedia ConGen-IndoBERT Base 80.47 125M IndoBERT Base paraphrase-multilingual-mpnet-base-v2 Wikipedia ConGen-SimCSE-IndoBERT Base 81.16 125M SimCSE-IndoBERT Base paraphrase-multilingual-mpnet-base-v2 Wikipedia"},{"location":"unsupervised_learning/ConGen/#references","title":"References","text":"<pre><code>@inproceedings{limkonchotiwat-etal-2022-congen,\ntitle = \"{ConGen}: Unsupervised Control and Generalization Distillation For Sentence Representation\",\nauthor = \"Limkonchotiwat, Peerat  and\n    Ponwitayarat, Wuttikorn  and\n    Lowphansirikul, Lalita and\n    Udomcharoenchaikit, Can  and\n    Chuangsuwanich, Ekapol  and\n    Nutanong, Sarana\",\nbooktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\nyear = \"2022\",\npublisher = \"Association for Computational Linguistics\",\n}\n</code></pre>"},{"location":"unsupervised_learning/SimCSE/","title":"SimCSE","text":"<p>Unsupervised SimCSE is a contrastive learning framework that proposes the usage of different dropout masks as means to generate augmented representations of the same text. There is also a supervised variant of SimCSE that leverages annoated pairs from NLI datasets, using the same contrastive learning framework.</p> <p>Training via SimCSE requires an unsupervised corpus, which is readily available for Indonesian texts. In our experiments, we used Wikipedia texts. We used the Sentence Transformer implementation of SimCSE.</p>"},{"location":"unsupervised_learning/SimCSE/#unsupervised-simcse-with-multiplenegativesrankingloss","title":"Unsupervised SimCSE with MultipleNegativesRankingLoss","text":""},{"location":"unsupervised_learning/SimCSE/#indobert-base","title":"IndoBERT Base","text":"<pre><code>python train_sim_cse.py \\\n--model-name indobenchmark/indobert-base-p1 \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-train-samples 1000000 \\\n--max-seq-length 32 \\\n--num-epochs 1 \\\n--train-batch-size 128 \\\n--learning-rate 3e-5\n</code></pre>"},{"location":"unsupervised_learning/SimCSE/#indobert-lite-base","title":"IndoBERT Lite Base","text":"<pre><code>python train_sim_cse.py \\\n--model-name indobenchmark/indobert-lite-base-p1 \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-train-samples 1000000 \\\n--max-seq-length 75 \\\n--num-epochs 1 \\\n--train-batch-size 128 \\\n--learning-rate 3e-5\n</code></pre>"},{"location":"unsupervised_learning/SimCSE/#indoroberta-base","title":"IndoRoBERTa Base","text":"<pre><code>python train_sim_cse.py \\\n--model-name flax-community/indonesian-roberta-base \\\n--train-dataset-name LazarusNLP/wikipedia_id_20230520 \\\n--max-train-samples 1000000 \\\n--max-seq-length 32 \\\n--num-epochs 1 \\\n--train-batch-size 128 \\\n--learning-rate 3e-5\n</code></pre>"},{"location":"unsupervised_learning/SimCSE/#results","title":"Results","text":""},{"location":"unsupervised_learning/SimCSE/#stsb-mt-id","title":"STSB-MT-ID","text":"Model Spearman's Correlation (%) #params Base Model Train Dataset SimCSE-IndoBERT Lite Base 44.08 12M IndoBERT Lite Base Wikipedia SimCSE-IndoRoBERTa Base 61.26 125M IndoRoBERTa Base Wikipedia SimCSE-IndoBERT Base 70.13 125M IndoBERT Base Wikipedia"},{"location":"unsupervised_learning/SimCSE/#references","title":"References","text":"<pre><code>@inproceedings{gao2021simcse,\ntitle={{SimCSE}: Simple Contrastive Learning of Sentence Embeddings},\nauthor={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},\nbooktitle={Empirical Methods in Natural Language Processing (EMNLP)},\nyear={2021}\n}\n</code></pre>"}]}